{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyP+E24aF3V1zUQmsbRvh+fa",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shiwoei-ai/ai_tech_and_biz_app_course/blob/main/workshop3A_r1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "2sx6JOawgZui"
      },
      "outputs": [],
      "source": [
        "# 1. 程式執行環境的準備\n",
        "# 載入必要套件\n",
        "\n",
        "# 載入標準數據分析、畫圖套件\n",
        "# 載入可以協助清楚呈現與評估分類模型表現的套件\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "\n",
        "# 載入建立類神經網路模型所需套件\n",
        "# 因為要建立 CNN 模型，所以把用於建立卷積層\n",
        "# 及池化層的基本元件讀進來。\n",
        "# Conv2D, MaxPooling2D 當然是 CNN 必備的，\n",
        "# 而 Flatten 則可以把最後一個個記分板（特徵圖）\n",
        "# 攤平並合併成為一個向量。\n",
        "from tensorflow.keras.datasets import mnist\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.layers import Flatten, Conv2D, MaxPooling2D\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "\n",
        "# 讓圖直接在 notebook 中顯示\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 2. 資料載入及檢查（Loading Data）\n",
        "# 由於我們已經在使用全連結神經網路建模時檢查過這筆資料，\n",
        "# 所以我們在這個程式中就不再多做額外的檢查。\n",
        "# 不熟悉這筆資料的同學可參考 Workshop 2A 的程式碼。\n",
        "\n",
        "# 載入 MNIST 手寫數字資料集\n",
        "# MNIST 資料集包含 60,000 張訓練圖像與 10,000 張測試圖像，\n",
        "# 每張圖為 28x28 灰階圖\n",
        "(X_train, y_train), (X_test, y_test) = mnist.load_data()"
      ],
      "metadata": {
        "id": "_8NT6-rlgvwD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 3. 資料前處理\n",
        "# 將影像資料 reshape 成 CNN 可接受的格式\n",
        "# （samples, height, width, channels）\n",
        "# 其中 samples 是指有多少筆資料（多少張圖片），\n",
        "# height 與 width 則是圖片的高與寬，\n",
        "# 而最後的 channels 是指輸入圖片的通道數。\n",
        "# 如果是用 RGB 三種顏色的彩色圖片，\n",
        "# 則通道數 channels = 3。\n",
        "# 但因為 MNIST 資料集只是灰階圖，\n",
        "# 所以只會有一個用來表示深淺的通道，\n",
        "# 所以 channels = 1。\n",
        "X_train = X_train.reshape(60000, 28, 28, 1).astype('float32')\n",
        "X_test = X_test.reshape(10000, 28, 28, 1).astype('float32')\n",
        "\n",
        "# 將像素值正規化（把 0-255 轉換成 0-1 之間的數據）\n",
        "# 這樣做可以加速模型收斂與提高穩定性\n",
        "X_train = X_train / 255.0\n",
        "X_test = X_test / 255.0\n",
        "\n",
        "# One-hot encoding 標籤\n",
        "# 為分類輸出所做的資料前處理\n",
        "# （因 MNIST 有 10 個類別，分別為數字 0~9）\n",
        "n_classes = 10\n",
        "y_train = to_categorical(y_train, n_classes)\n",
        "y_test = to_categorical(y_test, n_classes)"
      ],
      "metadata": {
        "id": "LT0V8CwSg5LF"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 4. 建立模型（Convolutional Neural Network，CNN）\n",
        "# 我們在此宣告 CNN 模型的結構\n",
        "# 在此考量的幾個簡單設計原則\n",
        "#\n",
        "# (1) 小卷積核 (3×3)\n",
        "# 3×3 已足以捕捉局部特徵，參數數量也比 5×5 少。\n",
        "#\n",
        "# (2) 逐層加深 + 池化降維\n",
        "# 用少數卷積層（2–3 層）搭配 MaxPooling，\n",
        "# 讓模型能抓到由低階到高階的特徵。\n",
        "#\n",
        "# (3) 使用 Dropout 防止過擬合\n",
        "# 雖然 MNIST 不大，但簡單的 Dropout 仍能讓模型泛化更好。\n",
        "#\n",
        "# (4) 參數量適中\n",
        "# 控制參數量讓計算負擔不至太大，但效能足以突破 Dense NN。\n",
        "\n",
        "\n",
        "# 首先，建立一個空的序列模型（Sequential）\n",
        "model = Sequential()\n",
        "\n",
        "# Block 1: 卷積 + 池化\n",
        "# 使用兩層 3x3 卷積，讓模型學習局部邊緣/筆劃特徵\n",
        "model.add(Conv2D(32,(3,3),padding=\"same\",\n",
        "                        activation=\"relu\",\n",
        "                        input_shape=(28, 28, 1)))\n",
        "model.add(Conv2D(32,(3,3),padding=\"same\",activation=\"relu\"))\n",
        "# 用 MaxPooling 將 feature map 壓縮成一半大小\n",
        "model.add(MaxPooling2D((2,2)))\n",
        "# 用 Dropout 隨機丟棄 25% 的神經元，降低過擬合\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "\n",
        "# Block 2: 更深一層卷積\n",
        "# 增加 filter 數量到 64，學習更複雜的形狀\n",
        "model.add(Conv2D(64,(3,3),padding=\"same\",activation=\"relu\"))\n",
        "model.add(Conv2D(64,(3,3),padding=\"same\",activation=\"relu\"))\n",
        "model.add(MaxPooling2D((2,2)))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "\n",
        "# 分類器（全連接層）\n",
        "# Flatten：把 feature map 攤平成一維向量\n",
        "model.add(Flatten())\n",
        "# Dense(128)：小型隱藏層，負責整合特徵\n",
        "model.add(Dense(128,activation=\"relu\"))\n",
        "# Dropout(0.5)：在分類頭加強正則化，避免過擬合\n",
        "model.add(Dropout(0.5))\n",
        "# 輸出層：10 個類別，使用 softmax\n",
        "model.add(Dense(n_classes,activation=\"softmax\"))\n",
        "\n",
        "\n",
        "# 顯示模型摘要\n",
        "# - 可以看到每層的輸入輸出尺寸、參數數量\n",
        "model.summary()\n"
      ],
      "metadata": {
        "id": "UCHDcRBficnv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 5. 編譯模型\n",
        "# 主要設定包括：\n",
        "# Optimizer: Adam（常見且穩定），\n",
        "# Loss: categorical_crossentropy（適用於多類別分類），\n",
        "# Metrics: accuracy（在訓練過程中提供「準確率」資訊）\n",
        "model.compile(\n",
        "    optimizer='Adam',\n",
        "    loss=\"categorical_crossentropy\",\n",
        "    metrics=[\"accuracy\"]\n",
        ")\n",
        "\n",
        "# 加入Callbacks 設定，包括\n",
        "# EarlyStopping：若驗證集 loss 連續 3 epoch 沒改善，\n",
        "#                就停止訓練並回復最佳權重\n",
        "# ModelCheckpoint：保存驗證準確率最佳的模型\n",
        "callbacks = [\n",
        "  EarlyStopping(monitor=\"val_loss\",\n",
        "                patience=3,\n",
        "                restore_best_weights=True),\n",
        "  ModelCheckpoint(\"mnist_cnn_best.keras\",\n",
        "                  monitor=\"val_accuracy\",\n",
        "                  save_best_only=True)\n",
        "]"
      ],
      "metadata": {
        "id": "e9QCCQ4XpQKE"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 6. 訓練模型\n",
        "# 以下程式碼的說明：\n",
        "# - X_train, y_train：訓練資料與標籤\n",
        "# - batch_size=128：訓練時用 128 筆樣本做為一批次（更新一次權重）\n",
        "# - epochs=15：完整訓練資料迭代 10 次\n",
        "# - verbose=1：訓練過程會顯示進度條與損失/準確率\n",
        "# - validation_data=(X_test, y_test)：在每個 epoch 結束後使用測試集評估模型表現\n",
        "model.fit(\n",
        "    X_train, y_train,\n",
        "    batch_size=128,\n",
        "    epochs=15,\n",
        "    verbose=1,\n",
        "    validation_data=(X_test, y_test)\n",
        ")"
      ],
      "metadata": {
        "id": "7xOM6GYHrHRk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 7. 評估模型\n",
        "\n",
        "# 對測試集進行初步評估（loss 和 accuracy）\n",
        "test_loss, test_acc = model.evaluate(X_test, y_test, verbose=1)\n",
        "print(\"Test Loss:\", test_loss)\n",
        "print(\"Test Accuracy:\", test_acc)\n",
        "\n",
        "# 對測試集進行並產生混淆矩陣\n",
        "# 以進行不同數字的預測準確度報告\n",
        "y_pred = model.predict(X_test)\n",
        "y_pred_classes = np.argmax(y_pred, axis=1)      # 將預測結果轉成類別\n",
        "y_true_classes = np.argmax(y_test, axis=1)      # 將真實標籤轉成類別\n",
        "\n",
        "# 混淆矩陣\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "cm = confusion_matrix(y_true_classes, y_pred_classes)\n",
        "print(\"Confusion Matrix:\\n\", cm)\n",
        "\n",
        "# 分類報告（precision, recall, f1-score）\n",
        "report = classification_report(y_true_classes, y_pred_classes)\n",
        "print(\"Classification Report:\\n\", report)\n"
      ],
      "metadata": {
        "id": "9y9T47xPvgh0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 8. 輸入照片行實測\n",
        "# 顯示前 5 張圖片與預測結果\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "for i in range(5):\n",
        "    plt.imshow(X_test[i].reshape(X_test.shape[1], X_test.shape[2]), cmap='gray')\n",
        "    plt.title(f\"True: {y_true_classes[i]}, Pred: {y_pred_classes[i]}\")\n",
        "    plt.axis('off')\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "r_Rhkqt2v7UN"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}