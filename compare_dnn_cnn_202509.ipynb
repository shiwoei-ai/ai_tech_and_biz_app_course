{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shiwoei-ai/ai_tech_and_biz_app_course/blob/main/compare_dnn_cnn_202509.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**步驟 1：環境設定與導入函式庫**"
      ],
      "metadata": {
        "id": "Y1t8U4_FOD_N"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RZLFJVJKODIM"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.datasets import mnist\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "from tensorflow.keras.optimizers import SGD\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "import ipywidgets as widgets\n",
        "from IPython.display import display, clear_output, HTML\n",
        "\n",
        "# 下載台北思源黑體\n",
        "!wget -O TaipeiSansTCBeta-Regular.ttf https://drive.google.com/uc?id=1eGAsTN1HBpJAkeVM57_C7ccp7hbgSz3_&export=download\n",
        "import matplotlib as mpl\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.font_manager import fontManager\n",
        "\n",
        "fontManager.addfont('TaipeiSansTCBeta-Regular.ttf')\n",
        "mpl.rc('font', family='Taipei Sans TC Beta')\n",
        "\n",
        "# 安裝Gradio\n",
        "!pip install --upgrade gradio\n",
        "import gradio, sys\n",
        "print(\"Gradio version:\", gradio.__version__)\n",
        "print(\"Python:\", sys.version)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**步驟 2：載入、檢視與預處理MNIST資料集**"
      ],
      "metadata": {
        "id": "-y4-bqXROLqe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1.載入MNIST手寫數字資料集\n",
        "# MNIST資料集包含60,000張訓練圖像與10,000張測試圖像\n",
        "# 每張圖為28x28像素的灰階圖\n",
        "(X_train_raw, y_train_raw), (X_test_raw, y_test_raw) = mnist.load_data()\n",
        "\n",
        "# 看看第一張圖的資料長什麼樣子\n",
        "print(\"第一張圖的實際樣子：\\n\")\n",
        "np.set_printoptions(linewidth=np.inf)\n",
        "print(X_train_raw[0])\n",
        "\n",
        "# 畫出訓練資料最前面的12張圖\n",
        "print(\"\\n訓練資料最前面的12張圖：\\n\")\n",
        "plt.figure(figsize=(5,5))\n",
        "for k in range(12):\n",
        "  plt.subplot(3, 4, k+1)\n",
        "  plt.imshow(X_train_raw[k], cmap='gray')\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# 2. 資料正規化(Normalization)\n",
        "# 將像素值從0-255的範圍，縮放到0-1之間，有助於加速模型收斂\n",
        "X_train_normalized = X_train_raw / 255.0\n",
        "X_test_normalized = X_test_raw / 255.0\n",
        "\n",
        "# 再看看第一張圖的資料長什麼樣子\n",
        "print(\"\\n再看看第一張圖正規化後長什麼樣子：\\n\")\n",
        "print(X_train_normalized[0])\n",
        "\n",
        "# 3. 類別標籤One-hot編碼\n",
        "# 將數字0-9的標籤轉換為向量形式，例如3->[0,0,0,1,0,0,0,0,0,0]\n",
        "n_classes = 10\n",
        "y_train = to_categorical(y_train_raw, n_classes)\n",
        "y_test = to_categorical(y_test_raw, n_classes)\n",
        "\n",
        "print(f\"訓練資料維度: {X_train_normalized.shape}\")\n",
        "print(f\"測試資料維度: {X_test_normalized.shape}\")\n",
        "print(f\"訓練標籤維度: {y_train.shape}\")\n",
        "print(f\"測試標籤維度: {y_test.shape}\")"
      ],
      "metadata": {
        "id": "1L0LlXqOOUV6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**步驟 3：建立與訓練 DNN 模型**"
      ],
      "metadata": {
        "id": "uILvbyNMOXv3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1.為了DNN，需將28x28的圖像展平成784維的向量\n",
        "X_train_dnn = X_train_normalized.reshape(60000, 784)\n",
        "X_test_dnn = X_test_normalized.reshape(10000, 784)\n",
        "\n",
        "# 2.建立DNN模型結構\n",
        "model_dnn = Sequential([\n",
        "    # input_shape只需設定在第一層\n",
        "    Dense(64,activation='relu',input_shape=(784,)),\n",
        "    Dropout(0.2),\n",
        "    Dense(32,activation='relu'),\n",
        "    Dropout(0.2),\n",
        "    Dense(32,activation='relu'),\n",
        "    Dropout(0.2),\n",
        "    # 輸出層有10個神經元，對應0-9十個數字，使用softmax輸出機率\n",
        "    Dense(n_classes, activation='softmax')\n",
        "])\n",
        "\n",
        "# 3.編譯模型 (Compile)\n",
        "# optimizer:採用SGD\n",
        "# loss:損失函數，多分類問題適用categorical_crossentropy\n",
        "# metrics:評估指標，我們關心的是準確率(accuracy)\n",
        "model_dnn.compile(loss='categorical_crossentropy',optimizer=SGD(learning_rate=0.087), metrics=['accuracy'])\n",
        "\n",
        "# 4.顯示模型摘要\n",
        "print(\"--- DNN 模型結構 ---\")\n",
        "model_dnn.summary()\n",
        "\n",
        "# 5.訓練模型\n",
        "print(\"\\n--- 開始訓練 DNN 模型 ---\")\n",
        "history_dnn = model_dnn.fit(X_train_dnn, y_train,\n",
        "                      epochs=20,\n",
        "                      batch_size=128,\n",
        "                      validation_split=0.1, # 劃分部分訓練資料做為驗證集\n",
        "                      verbose=1)"
      ],
      "metadata": {
        "id": "iXnW9hAdOq2A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**步驟 4：評估 DNN 模型成效**"
      ],
      "metadata": {
        "id": "yrNrpMebOulO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1.在測試集上評估模型\n",
        "print(\"--- 評估 DNN 模型 ---\")\n",
        "loss_dnn, acc_dnn = model_dnn.evaluate(X_test_dnn, y_test, verbose=0)\n",
        "print(f\"DNN測試集準確率 (Accuracy): {acc_dnn:.4f}\")\n",
        "\n",
        "# 2.產生預測\n",
        "y_pred_dnn_proba = model_dnn.predict(X_test_dnn)\n",
        "y_pred_dnn = np.argmax(y_pred_dnn_proba, axis=1)\n",
        "\n",
        "# 3.繪製混淆矩陣\n",
        "cm_dnn = confusion_matrix(y_test_raw, y_pred_dnn)\n",
        "plt.figure(figsize=(10, 8))\n",
        "sns.heatmap(cm_dnn, annot=True, fmt='d', cmap='Blues')\n",
        "plt.title('DNN 模型 - 混淆矩陣 (Confusion Matrix)')\n",
        "plt.ylabel('真實標籤 (Actual Label)')\n",
        "plt.xlabel('預測標籤 (Predicted Label)')\n",
        "plt.show()\n",
        "\n",
        "print(\"\\n從準確率與混淆矩陣可以看出，DNN表現不錯，但在某些數字上仍有改進空間。\")\n",
        "print(\"接下來，我們將嘗試使用專為圖像設計的CNN模型，看看是否能獲得更好的結果。\")"
      ],
      "metadata": {
        "id": "zqQIUVrQOyyA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**步驟 5：建立與訓練 CNN 模型**"
      ],
      "metadata": {
        "id": "OzwMLXCoO0vh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1.為了CNN，需將資料調整為(樣本數,高,寬,色彩頻道)的格式\n",
        "# MNIST是灰階圖，所以色彩頻道(channel)為1\n",
        "X_train_cnn = X_train_normalized.reshape(60000, 28, 28, 1)\n",
        "X_test_cnn = X_test_normalized.reshape(10000, 28, 28, 1)\n",
        "\n",
        "# 2.建立CNN模型結構(保持原notebook的參數)\n",
        "model_cnn = Sequential([\n",
        "    # 第一個卷積層：32 個3x3 的濾波器 (filter)\n",
        "    # -input_shape=(28,28,1)表示輸入影像大小為28x28，單通道(灰階)\n",
        "    Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=(28, 28, 1)),\n",
        "    # 第二個卷積層：64 個 3x3 的濾波器\n",
        "    Conv2D(64, kernel_size=(3, 3), activation='relu'),\n",
        "    # 將特徵圖縮小一半 (2x2 池化)，減少參數量並提取重要特徵\n",
        "    MaxPooling2D(pool_size=(2, 2)),\n",
        "    Dropout(0.25),\n",
        "    # 展平層：將2D特徵圖轉為1D，以接入全連接層\n",
        "    Flatten(),\n",
        "    # 全連接層(Dense Layer)\n",
        "    Dense(128, activation='relu'),\n",
        "    Dropout(0.5),\n",
        "    # 輸出層\n",
        "    Dense(n_classes, activation='softmax')\n",
        "])\n",
        "\n",
        "# 3.編譯模型\n",
        "model_cnn.compile(optimizer='adam',\n",
        "          loss='categorical_crossentropy',\n",
        "          metrics=['accuracy'])\n",
        "\n",
        "# 4.顯示模型摘要\n",
        "print(\"--- CNN 模型結構 ---\")\n",
        "model_cnn.summary()\n",
        "\n",
        "# 5.訓練模型\n",
        "print(\"\\n--- 開始訓練 CNN 模型 ---\")\n",
        "history_cnn = model_cnn.fit(X_train_cnn, y_train,\n",
        "                      epochs=10,\n",
        "                      batch_size=128,\n",
        "                      validation_data=(X_test_cnn, y_test),\n",
        "                      verbose=1)"
      ],
      "metadata": {
        "id": "MdYC7QWNO6RC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**步驟 6：評估 CNN 模型成效**"
      ],
      "metadata": {
        "id": "P0rCcD_5O75Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1.在測試集上評估模型\n",
        "print(\"--- 評估 CNN 模型 ---\")\n",
        "loss_cnn, acc_cnn = model_cnn.evaluate(X_test_cnn, y_test, verbose=0)\n",
        "print(f\"CNN 測試集準確率 (Accuracy): {acc_cnn:.4f}\")\n",
        "\n",
        "# 2.產生預測\n",
        "y_pred_cnn_proba = model_cnn.predict(X_test_cnn)\n",
        "y_pred_cnn = np.argmax(y_pred_cnn_proba, axis=1)\n",
        "\n",
        "# 3.繪製混淆矩陣\n",
        "cm_cnn = confusion_matrix(y_test_raw, y_pred_cnn)\n",
        "plt.figure(figsize=(10, 8))\n",
        "sns.heatmap(cm_cnn, annot=True, fmt='d', cmap='Blues')\n",
        "plt.title('CNN 模型 - 混淆矩陣 (Confusion Matrix)')\n",
        "plt.ylabel('真實標籤 (Actual Label)')\n",
        "plt.xlabel('預測標籤 (Predicted Label)')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "vwD-8t2oO_xG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**步驟 7：比較 DNN 與 CNN 成效**"
      ],
      "metadata": {
        "id": "i4XUdAMrPCGm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 最終成效比較\n",
        "comparison_html = f\"\"\"\n",
        "<h3 style=\"font-family: 'Microsoft JhengHei', sans-serif;\">最終成效總結</h3>\n",
        "<table border=\"1\" style=\"width:60%; text-align:center; font-family: 'Arial', sans-serif; border-collapse: collapse;\">\n",
        "  <tr style=\"background-color:#f2f2f2;\">\n",
        "    <th style=\"padding: 8px;\">模型 (Model)</th>\n",
        "    <th style=\"padding: 8px;\">測試集損失 (Test Loss)</th>\n",
        "    <th style=\"padding: 8px;\">測試集準確率 (Test Accuracy)</th>\n",
        "  </tr>\n",
        "  <tr>\n",
        "    <td style=\"padding: 8px;\"><b>深度神經網路 (DNN)</b></td>\n",
        "    <td style=\"padding: 8px;\">{loss_dnn:.4f}</td>\n",
        "    <td style=\"padding: 8px;\"><font size='+1'>{acc_dnn:.4f}</font></td>\n",
        "  </tr>\n",
        "  <tr>\n",
        "    <td style=\"padding: 8px;\"><b>卷積神經網路 (CNN)</b></td>\n",
        "    <td style=\"padding: 8px;\"><b>{loss_cnn:.4f}</b></td>\n",
        "    <td style=\"padding: 8px;\"><font size='+1' color='blue'><b>{acc_cnn:.4f}</b></font></td>\n",
        "  </tr>\n",
        "</table>\n",
        "\"\"\"\n",
        "\n",
        "display(HTML(comparison_html))"
      ],
      "metadata": {
        "id": "egFQLYPYPYwn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**步驟 8：互動式預測 Web App**"
      ],
      "metadata": {
        "id": "Em1Zq9baPQ2P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 單數字辨識\n",
        "\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import gradio as gr\n",
        "import inspect\n",
        "\n",
        "# 1.影像前處理\n",
        "def preprocess_image(img_np: np.ndarray) -> np.ndarray:\n",
        "    if img_np is None:\n",
        "        return np.zeros((28, 28), dtype=np.float32)\n",
        "    img = Image.fromarray(img_np).convert(\"L\")\n",
        "    gray = np.array(img).astype(np.uint8)\n",
        "    if gray.mean() > 127:  # 容錯：白底黑字就反相\n",
        "        gray = 255 - gray\n",
        "    thresh = 20\n",
        "    fg = gray > thresh\n",
        "    if not np.any(fg):\n",
        "        return np.zeros((28, 28), dtype=np.float32)\n",
        "    rows = np.where(fg.any(axis=1))[0]\n",
        "    cols = np.where(fg.any(axis=0))[0]\n",
        "    rmin, rmax = rows[0], rows[-1] + 1\n",
        "    cmin, cmax = cols[0], cols[-1] + 1\n",
        "    cropped = gray[rmin:rmax, cmin:cmax]\n",
        "    h, w = cropped.shape\n",
        "    side = max(h, w)\n",
        "    square = np.zeros((side, side), dtype=np.uint8)\n",
        "    r_off = (side - h) // 2\n",
        "    c_off = (side - w) // 2\n",
        "    square[r_off:r_off + h, c_off:c_off + w] = cropped\n",
        "    square_img = Image.fromarray(square).resize((20, 20), Image.Resampling.LANCZOS)\n",
        "    canvas = np.zeros((28, 28), dtype=np.uint8)\n",
        "    canvas[4:24, 4:24] = np.array(square_img)\n",
        "    return canvas.astype(\"float32\") / 255.0\n",
        "\n",
        "# 2.推論\n",
        "def recognize_digit_dual(drawing):\n",
        "    if drawing is None:\n",
        "        return {}, {}\n",
        "    if isinstance(drawing, dict):\n",
        "        arr = drawing.get(\"image\") or drawing.get(\"composite\")\n",
        "    else:\n",
        "        arr = drawing\n",
        "    if arr is None:\n",
        "        return {}, {}\n",
        "    processed = preprocess_image(np.array(arr))\n",
        "    x_dnn = processed.reshape(1, 784)\n",
        "    x_cnn = processed.reshape(1, 28, 28, 1)\n",
        "    dnn_proba = model_dnn.predict(x_dnn, verbose=0)[0]\n",
        "    cnn_proba = model_cnn.predict(x_cnn, verbose=0)[0]\n",
        "    labels = [str(i) for i in range(10)]\n",
        "    return (\n",
        "        {labels[i]: float(dnn_proba[i]) for i in range(10)},\n",
        "        {labels[i]: float(cnn_proba[i]) for i in range(10)}\n",
        "    )\n",
        "\n",
        "# 3.黑色底圖\n",
        "def make_black_canvas(w=336, h=336, channels=3):\n",
        "    if channels == 1:\n",
        "        return np.zeros((h, w), dtype=np.uint8)\n",
        "    return np.zeros((h, w, channels), dtype=np.uint8)\n",
        "\n",
        "black_canvas = make_black_canvas(336, 336, 3)\n",
        "\n",
        "# 選擇繪圖元件\n",
        "use_image_editor = hasattr(gr, \"ImageEditor\")\n",
        "sketchpad_has_style_args = all(\n",
        "    x in str(inspect.signature(gr.Sketchpad.__init__))\n",
        "    for x in [\"background_color\", \"brush_color\", \"stroke_width\"]\n",
        ") if hasattr(gr, \"Sketchpad\") else False\n",
        "\n",
        "with gr.Blocks(title=\"✏️ MNIST 手寫數字辨識 - DNN vs. CNN（黑底白筆版）\") as demo:\n",
        "    gr.Markdown(\"把數字寫在**左側黑色畫布**中央，按提交；右側會顯示兩個模型的 top-3 結果。\")\n",
        "\n",
        "    with gr.Row():\n",
        "        # 左側：畫布+按鈕\n",
        "        with gr.Column(scale=1):\n",
        "            if use_image_editor:\n",
        "                draw = gr.ImageEditor(\n",
        "                    value=black_canvas, height=360, width=360,\n",
        "                    label=\"左側畫布（請選白色筆刷、筆寬約 20）\"\n",
        "                )\n",
        "                reset_value = black_canvas\n",
        "            elif sketchpad_has_style_args:\n",
        "                draw = gr.Sketchpad(\n",
        "                    height=336, width=336,\n",
        "                    background_color=\"black\", brush_color=\"white\", stroke_width=20,\n",
        "                    label=\"左側黑色畫布\"\n",
        "                )\n",
        "                reset_value = None\n",
        "            else:\n",
        "                draw = gr.Sketchpad(\n",
        "                    height=336, width=336,\n",
        "                    label=\"左側畫布（白底備案，系統會自動反相）\"\n",
        "                )\n",
        "                reset_value = None\n",
        "\n",
        "            with gr.Row():\n",
        "                btn_submit = gr.Button(\"提交\", variant=\"primary\")\n",
        "                btn_clear  = gr.Button(\"清除\", variant=\"secondary\")\n",
        "\n",
        "        # 右側：結果\n",
        "        with gr.Column(scale=1):\n",
        "            dnn_label = gr.Label(num_top_classes=3, label=\"DNN 模型預測結果\")\n",
        "            cnn_label = gr.Label(num_top_classes=3, label=\"CNN 模型預測結果\")\n",
        "\n",
        "    btn_submit.click(fn=recognize_digit_dual, inputs=draw, outputs=[dnn_label, cnn_label])\n",
        "\n",
        "    def _reset():\n",
        "        return reset_value, {}, {}\n",
        "    btn_clear.click(fn=_reset, inputs=None, outputs=[draw, dnn_label, cnn_label])\n",
        "\n",
        "demo.launch(debug=True)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 625
        },
        "id": "PIQuMFarPUEZ",
        "outputId": "eb4cafc3-b4bb-4b85-cee9-e48405d8fece"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "It looks like you are running Gradio on a hosted Jupyter notebook, which requires `share=True`. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. This cell will run indefinitely so that you can see errors and logs. To turn off, set debug=False in launch().\n",
            "* Running on public URL: https://ee918205ce1a197d8d.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://ee918205ce1a197d8d.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 多數字辨識\n",
        "\n",
        "import numpy as np\n",
        "from PIL import Image, ImageDraw, ImageFont\n",
        "import gradio as gr\n",
        "from collections import deque\n",
        "\n",
        "def _center_resize_to_mnist(gray: np.ndarray) -> np.ndarray:\n",
        "    # gray: uint8 0~255，黑底白字\n",
        "    thresh = 20\n",
        "    fg = gray > thresh\n",
        "    if not np.any(fg):\n",
        "        return np.zeros((28, 28), dtype=np.float32)\n",
        "\n",
        "    rows = np.where(fg.any(axis=1))[0]\n",
        "    cols = np.where(fg.any(axis=0))[0]\n",
        "    rmin, rmax = rows[0], rows[-1] + 1\n",
        "    cmin, cmax = cols[0], cols[-1] + 1\n",
        "    cropped = gray[rmin:rmax, cmin:cmax]\n",
        "\n",
        "    h, w = cropped.shape\n",
        "    side = max(h, w)\n",
        "    square = np.zeros((side, side), dtype=np.uint8)\n",
        "    r_off = (side - h) // 2\n",
        "    c_off = (side - w) // 2\n",
        "    square[r_off:r_off + h, c_off:c_off + w] = cropped\n",
        "\n",
        "    img20 = Image.fromarray(square).resize((20, 20), Image.Resampling.LANCZOS)\n",
        "    canvas = np.zeros((28, 28), dtype=np.uint8)\n",
        "    canvas[4:24, 4:24] = np.array(img20)\n",
        "    return (canvas.astype(\"float32\") / 255.0)\n",
        "\n",
        "def _connected_components_bboxes(bin_fg: np.ndarray, min_area=60, max_components=80):\n",
        "    H, W = bin_fg.shape\n",
        "    visited = np.zeros_like(bin_fg, dtype=bool)\n",
        "    bboxes = []\n",
        "    dirs = [(1,0),(-1,0),(0,1),(0,-1)]\n",
        "\n",
        "    for r0 in range(H):\n",
        "        for c0 in range(W):\n",
        "            if not bin_fg[r0, c0] or visited[r0, c0]:\n",
        "                continue\n",
        "            q = deque([(r0, c0)])\n",
        "            visited[r0, c0] = True\n",
        "            rmin=rmax=r0; cmin=cmax=c0; area=0\n",
        "            while q:\n",
        "                r, c = q.popleft()\n",
        "                area += 1\n",
        "                if r < rmin: rmin = r\n",
        "                if r > rmax: rmax = r\n",
        "                if c < cmin: cmin = c\n",
        "                if c > cmax: cmax = c\n",
        "                for dr, dc in dirs:\n",
        "                    nr, nc = r+dr, c+dc\n",
        "                    if 0 <= nr < H and 0 <= nc < W and bin_fg[nr, nc] and not visited[nr, nc]:\n",
        "                        visited[nr, nc] = True\n",
        "                        q.append((nr, nc))\n",
        "            if area >= min_area:\n",
        "                bboxes.append((rmin, rmax+1, cmin, cmax+1, area))\n",
        "                if len(bboxes) >= max_components:\n",
        "                    break\n",
        "        if len(bboxes) >= max_components:\n",
        "            break\n",
        "    return bboxes\n",
        "\n",
        "def detect_multi_digits(drawing):\n",
        "    if drawing is None:\n",
        "        return None, [], \"\", \"\"\n",
        "    if isinstance(drawing, dict):\n",
        "        arr = drawing.get(\"image\") or drawing.get(\"composite\")\n",
        "    else:\n",
        "        arr = drawing\n",
        "    if arr is None:\n",
        "        return None, [], \"\", \"\"\n",
        "\n",
        "    rgb = np.array(arr)\n",
        "    gray = np.array(Image.fromarray(rgb).convert(\"L\")).astype(np.uint8)\n",
        "\n",
        "    if gray.mean() > 127:\n",
        "        gray = 255 - gray\n",
        "\n",
        "    fg = gray > 20\n",
        "    bboxes = _connected_components_bboxes(fg, min_area=60, max_components=80)\n",
        "\n",
        "    bboxes.sort(key=lambda b: (b[2], b[0]))\n",
        "\n",
        "    labels = [str(i) for i in range(10)]\n",
        "    rows = []\n",
        "    seq_cnn, seq_dnn = [], []\n",
        "\n",
        "    draw_img = Image.fromarray(rgb).convert(\"RGB\")\n",
        "    draw = ImageDraw.Draw(draw_img)\n",
        "    try:\n",
        "        font = ImageFont.load_default()\n",
        "    except:\n",
        "        font = None\n",
        "\n",
        "    for idx, (rmin, rmax, cmin, cmax, area) in enumerate(bboxes, start=1):\n",
        "        crop = gray[rmin:rmax, cmin:cmax]\n",
        "        mn = _center_resize_to_mnist(crop)\n",
        "        xd = mn.reshape(1, 784)\n",
        "        xc = mn.reshape(1, 28, 28, 1)\n",
        "\n",
        "        proba_d = model_dnn.predict(xd, verbose=0)[0]\n",
        "        proba_c = model_cnn.predict(xc, verbose=0)[0]\n",
        "\n",
        "        pred_d, conf_d = int(np.argmax(proba_d)), float(np.max(proba_d))\n",
        "        pred_c, conf_c = int(np.argmax(proba_c)), float(np.max(proba_c))\n",
        "\n",
        "        seq_dnn.append(str(pred_d))\n",
        "        seq_cnn.append(str(pred_c))\n",
        "\n",
        "        rows.append({\n",
        "            \"id\": idx,\n",
        "            \"bbox\": (int(rmin), int(cmin), int(rmax), int(cmax)),\n",
        "            \"pred_dnn\": pred_d, \"conf_dnn\": round(conf_d, 4),\n",
        "            \"pred_cnn\": pred_c, \"conf_cnn\": round(conf_c, 4),\n",
        "            \"area\": int(area)\n",
        "        })\n",
        "\n",
        "        draw.rectangle([cmin, rmin, cmax, rmax], outline=(0,255,0), width=2)\n",
        "        draw.text((cmin+2, rmin+2), f\"{pred_c}\", fill=(255,255,0), font=font)\n",
        "\n",
        "    annotated = np.array(draw_img)\n",
        "    seq_text_cnn = \"\".join(seq_cnn)\n",
        "    seq_text_dnn = \"\".join(seq_dnn)\n",
        "    return annotated, rows, seq_text_cnn, seq_text_dnn\n",
        "\n",
        "def make_black_canvas(h=360, w=720, channels=3):\n",
        "    return np.zeros((h, w, channels), dtype=np.uint8)\n",
        "\n",
        "black_canvas_big = make_black_canvas(360, 720, 3)\n",
        "\n",
        "with gr.Blocks(title=\"🧩 多數字辨識（DNN 與 CNN）\") as multi_digits_app:\n",
        "    gr.Markdown(\"在左側**黑色大畫布**寫下多個數字（建議筆寬≈20、數字間留些間隔）。提交後右側會顯示：\\\n",
        "    1) 綠框＋CNN數字的標註圖，2) CNN 與 DNN 的由左到右預測序列。\")\n",
        "\n",
        "    with gr.Row():\n",
        "        # 左側：畫布+按鈕\n",
        "        with gr.Column(scale=1):\n",
        "            if hasattr(gr, \"ImageEditor\"):\n",
        "                canvas = gr.ImageEditor(\n",
        "                    value=black_canvas_big,\n",
        "                    height=380, width=760,\n",
        "                    label=\"多數字畫布（黑底）：右上角選白色筆刷、筆寬約 20\"\n",
        "                )\n",
        "            else:\n",
        "                canvas = gr.Sketchpad(\n",
        "                    height=380, width=760,\n",
        "                    label=\"多數字畫布（若為白底，系統會自動反相）\"\n",
        "                )\n",
        "            with gr.Row():\n",
        "                btn_run = gr.Button(\"提交\", variant=\"primary\")\n",
        "                btn_clear = gr.Button(\"清除\", variant=\"secondary\")\n",
        "\n",
        "        # 右側：結果\n",
        "        with gr.Column(scale=1):\n",
        "            annotated_out = gr.Image(label=\"標註結果（綠框 + CNN 預測數字）\")\n",
        "            # table_out = gr.Dataframe(\n",
        "            #     headers=[\"id\",\"bbox\",\"pred_dnn\",\"conf_dnn\",\"pred_cnn\",\"conf_cnn\",\"area\"],\n",
        "            #     datatype=[\"number\",\"str\",\"number\",\"number\",\"number\",\"number\",\"number\"],\n",
        "            #     label=\"逐個數字的預測表（DNN / CNN）\",\n",
        "            #     interactive=False\n",
        "            # )\n",
        "            seq_out_cnn = gr.Textbox(label=\"由左到右的 CNN 預測序列\", interactive=False)\n",
        "            seq_out_dnn = gr.Textbox(label=\"由左到右的 DNN 預測序列\", interactive=False)\n",
        "\n",
        "    # 提交推論\n",
        "    btn_run.click(\n",
        "        fn=detect_multi_digits,\n",
        "        inputs=canvas,\n",
        "        outputs=[annotated_out, table_out, seq_out_cnn, seq_out_dnn]\n",
        "    )\n",
        "\n",
        "    def _reset_multi():\n",
        "        return black_canvas_big, None, [], \"\", \"\"\n",
        "    btn_clear.click(\n",
        "        fn=_reset_multi,\n",
        "        inputs=None,\n",
        "        outputs=[canvas, annotated_out, table_out, seq_out_cnn, seq_out_dnn]\n",
        "    )\n",
        "\n",
        "multi_digits_app.launch(debug=True)\n"
      ],
      "metadata": {
        "id": "CfNDrVMFYMsB"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}