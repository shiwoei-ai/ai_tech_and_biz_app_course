{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNy7oaUBlCMO0vg8MdvN6Y4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shiwoei-ai/ai_tech_and_biz_app_course/blob/main/workshop_3B_r2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9xf8LDwxgdZh"
      },
      "outputs": [],
      "source": [
        "# 遷移模型實作\n",
        "# 透過遷移式學習進行八哥辨視\n",
        "# 本程式碼參考政大蔡炎龍教授「少年Py的大冒險：\n",
        "# 成為Python AI深度學習達人的第一門課」書中案例。\n",
        "# 本課程陳煒翔助教協助修改程式。\n",
        "\n",
        "# ==================================================\n",
        "# 1. 程式執行環境的準備\n",
        "# 載入必要套件\n",
        "\n",
        "# 載入標準數據分析、畫圖套件\n",
        "# 載入可以協助清楚呈現與評估分類模型表現的套件\n",
        "\n",
        "# 載入標準數據分析、畫圖、檔案處理等基礎套件\n",
        "# - numpy/pandas：資料處理的基本工具。pandas 在本例中未直接\n",
        "#   使用，但保留 import 可維持與原教材/環境一致。\n",
        "# - matplotlib：視覺化（畫圖、顯示結果、中文字體設定等）。\n",
        "# - os/zipfile：處理檔案路徑、解壓縮資料集。\n",
        "# - 在 Colab 上存取 /content/ 目錄最直觀。\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import zipfile\n",
        "\n",
        "# 載入可以協助清楚呈現與評估分類模型表現的套件：\n",
        "# - confusion_matrix：用矩陣形式檢視各類別的預測/真實值對照。\n",
        "# - classification_report：輸出 precision/recall/F1/支援度。\n",
        "# - 在模型評估（Step 7）階段會派上用場。\n",
        "\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "\n",
        "\n",
        "# 載入 TensorFlow Keras 所需的模組\n",
        "# - ResNet50V2：本工作坊案例採用遷移學習（transfer learning）。\n",
        "#   透過預訓練模型抽取通用影像特徵，再串接自己的分類頭（輸出層）。\n",
        "# - Sequential/Dense：以序列式串接各層、加入最後的 Dense 層。\n",
        "# - to_categorical：把標籤轉為 one-hot。\n",
        "# - preprocess_input：ResNetV2 專屬資料前處理（將像素轉到 [-1,1]）。\n",
        "# - load_img/img_to_array：載圖、轉成張量（H×W×C）。\n",
        "\n",
        "from tensorflow.keras.applications import ResNet50V2\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.applications.resnet_v2 import preprocess_input\n",
        "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
        "\n",
        "\n",
        "# 下載台北思源黑體（讓中文顯示更完整）\n",
        "# - 在 Colab/某些環境，預設中文字體不足，圖表中文字可能亂碼。\n",
        "# - 下載字型後，透過 matplotlib 設定預設字體，可確保中文正常顯示。\n",
        "# - 若在無網路的環境，請改為掛載雲端硬碟或本地安裝字型。\n",
        "\n",
        "!wget -O TaipeiSansTCBeta-Regular.ttf \\\n",
        "  \"https://drive.google.com/uc?id=1eGAsTN1HBpJAkeVM57_C7ccp7hbgSz3_&export=download\"\n",
        "\n",
        "import matplotlib as mpl\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.font_manager import fontManager\n",
        "\n",
        "# 將下載的字型註冊到 matplotlib，並設定為預設字型\n",
        "fontManager.addfont(\"TaipeiSansTCBeta-Regular.ttf\")\n",
        "mpl.rc(\"font\", family=\"Taipei Sans TC Beta\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ==================================================\n",
        "# 2. 資料載入及檢查（Loading Data）\n",
        "\n",
        "# 2.1 下載並解壓縮資料集\n",
        "# - 這裡直接用 wget 取得 GitHub 上的 myna（八哥）資料集。\n",
        "#   這是政大蔡炎龍教授準備的資料，他本身是方面的專家。\n",
        "# - --no-check-certificate：忽略 SSL 憑證檢查（避免憑證問題）。\n",
        "# - 下載後解壓縮到 /content/，便於後續用 os.listdir 逐檔讀取。\n",
        "#\n",
        "# 注意事項：\n",
        "# - 本教學/示範資料很小（只有 23 張），主要目的在於流程示範。\n",
        "#   真實商業應用需更多資料，並切分訓練/驗證/測試集避免過度擬合。\n",
        "\n",
        "!wget --no-check-certificate \\\n",
        "  https://github.com/yenlung/Deep-Learning-Basics/raw/master/images/myna.zip \\\n",
        "  -O /content/myna.zip\n",
        "\n",
        "local_zip = \"/content/myna.zip\"\n",
        "zip_ref = zipfile.ZipFile(local_zip, \"r\")\n",
        "zip_ref.extractall(\"/content\")\n",
        "zip_ref.close()\n",
        "\n",
        "\n",
        "# 2.2 讀取圖片並建立資料與標籤\n",
        "# - 直接將三個資料夾視為三個類別（0/1/2）。\n",
        "# - 以固定的 target_size=(256,256) 載入，確保輸入張量尺寸相同。\n",
        "# - img_to_array 會得到形狀 (H, W, C) 的 numpy 陣列（dtype=uint8）。\n",
        "# - 先把所有圖片堆疊到 data（list），標籤存到 target（list）。\n",
        "\n",
        "base_dir = \"/content/\"\n",
        "\n",
        "# 三類八哥對應的資料夾名稱（類別 0/1/2）\n",
        "myna_folders = [\"crested_myna\", \"javan_myna\", \"common_myna\"]\n",
        "\n",
        "# 以下標籤名稱主要用於後續顯示（包括混淆矩陣標軸、Gradio 介面等）\n",
        "labels = [\n",
        "    \"(土)八哥 (Crested Myna)\",\n",
        "    \"白尾八哥 (Javan Myna)\",\n",
        "    \"家八哥 (Common Myna)\"\n",
        "]\n",
        "\n",
        "data = []    # 存放影像資料（H×W×C）\n",
        "target = []  # 存放對應類別整數標籤（0/1/2）\n",
        "\n",
        "# 逐一走訪每個類別的資料夾\n",
        "for i in range(3):\n",
        "    thedir = base_dir + myna_folders[i]\n",
        "    # 取得該資料夾裡所有檔名（可能含非影像檔，實務上可再加判斷）\n",
        "    myna_fnames = os.listdir(thedir)\n",
        "\n",
        "    for myna in myna_fnames:\n",
        "        img_path = thedir + \"/\" + myna\n",
        "        # 載入圖片並統一縮放成 256×256，以利模型 batch 化處理\n",
        "        # 注意：此處未做資料清理（如壞檔、非影像），示範為主\n",
        "        img = load_img(img_path, target_size=(256, 256))\n",
        "        x = img_to_array(img)     # 轉成 numpy 陣列（像素 0–255）\n",
        "        data.append(x)            # 加入影像資料\n",
        "        target.append(i)          # 加入對應類別整數（0/1/2）\n",
        "\n",
        "# 轉成 numpy 陣列，模型輸入需要連續記憶體與統一 dtype/shape\n",
        "data = np.array(data)\n",
        "\n",
        "# 檢視資料維度：(樣本數, 高, 寬, 通道)\n",
        "# 例：(23, 256, 256, 3) 表示 23 張 256×256 的 RGB 影像\n",
        "print(\"資料維度:\", data.shape)"
      ],
      "metadata": {
        "id": "3kXr27sQgysK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ==================================================\n",
        "# 3. 資料前處理\n",
        "# 這裡分別針對輸入與輸出進行前處理，說明如下：\n",
        "# 1) preprocess_input（ResNetV2 版本）：\n",
        "#    - 會把像素從 [0,255] 按模型需求轉換到 [-1,1]。\n",
        "#    - 遷移學習時，務必要使用與預訓練模型相容的前處理，\n",
        "#      才能對齊特徵分布（否則效果大打折扣）。\n",
        "#    - 既然別的專家（ResNetV2）已經幫我們把這件事做好了，\n",
        "#      那我們就直接使用這些提供的與預訓練模型相容的前處理方法。\n",
        "# 2) to_categorical：把整數標籤（0/1/2）轉為 one-hot，如 [1,0,0]。\n",
        "\n",
        "x_train = preprocess_input(data)\n",
        "y_train = to_categorical(target, 3)\n",
        "\n",
        "print(\"第一筆資料的 One-Hot 編碼:\", y_train[0])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9ov5qAvqg8js",
        "outputId": "f9862f07-ff67-4f79-dbd0-c19c10b5c80f"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "第一筆資料的 One-Hot 編碼: [1. 0. 0.]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ==================================================\n",
        "# 4. 建立模型（遷移模型）\n",
        "#\n",
        "# 我們在此宣告遷移學習模型的設計結構：\n",
        "# - 使用 ResNet50V2（include_top=False 表示去掉 ImageNet 的 1000\n",
        "#   類別分類頭），保留其卷積骨幹作為特徵抽取器。\n",
        "# - pooling='avg'會把最後一層的 2048 個特徵圖（計分板）做平均，\n",
        "#   得到一個通道維度向量，參數量小、可降低過度擬合風險。\n",
        "# - 凍結參數（trainable=False）可避免在小數據上破壞預訓練權重。\n",
        "# - 只訓練自己加上的 Dense(3, softmax) 層，等於訓練一個分類頭。\n",
        "\n",
        "resnet = ResNet50V2(include_top=False, pooling=\"avg\")\n",
        "\n",
        "# 凍結骨幹網路權重以保留預訓練特徵（小數據情境特別重要）\n",
        "resnet.trainable = False\n",
        "\n",
        "# 以 Sequential 串接：\n",
        "# 以 ResNet50V2 做為骨幹 + 自訂輸出層（3 類 softmax）\n",
        "model = Sequential()\n",
        "model.add(resnet)\n",
        "model.add(Dense(3, activation=\"softmax\"))"
      ],
      "metadata": {
        "id": "XeXvtZeehI8e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ==================================================\n",
        "# 5. 編譯模型\n",
        "# - loss：categorical_crossentropy（多類別的標準損失函數）\n",
        "# - optimizer：adam（具有自適應學習率的優化器，收斂通常較穩定）\n",
        "# - metrics：accuracy（模型訓練過程中展示直觀指標）\n",
        "model.compile(\n",
        "    loss=\"categorical_crossentropy\",\n",
        "    optimizer=\"adam\",\n",
        "    metrics=[\"accuracy\"]\n",
        ")\n",
        "\n",
        "# 檢視模型摘要：\n",
        "# 可看到總參數數量（ResNet50V2 約有 2 千多萬個參數），\n",
        "# 但目前已凍結，所以可訓練參數僅剩最後 Dense 層（約 6147）。\n",
        "# 這對於本案例僅有 23 張訓練資料的情況很關鍵，\n",
        "# 可以降低過度擬合與訓練不穩定的情況。\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "U-YFpn5PhQ48"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ==================================================\n",
        "# 6. 訓練模型\n",
        "# - 本案例使用全部 23 張資料作為訓練資料，同時用於評估（僅為\n",
        "#   Demo）。真實專案務必切分 train/valid/test，或用交叉驗證。\n",
        "#   否則很可能出現過度擬合而不自知。\n",
        "# - batch_size=23：小數據可整批訓練，讓每個 epoch 僅一次權重更新。\n",
        "# - epochs=10：示範用；若資料更多/需要更好表現可增加並加入早停。\n",
        "\n",
        "print(\"開始訓練模型...\")\n",
        "model.fit(x_train, y_train, batch_size=23, epochs=10)\n",
        "print(\"模型訓練完成！\")"
      ],
      "metadata": {
        "id": "Fho3pyVYhbdY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ==================================================\n",
        "# 7. 評估模型\n",
        "# 以相同資料做 evaluate\n",
        "# 這僅是示範用，正式流程應使用留下來的測試集\n",
        "loss, acc = model.evaluate(x_train, y_train)\n",
        "print(f\"\\n最終損失 (Loss): {loss}\")\n",
        "print(f\"最終準確率 (Accuracy): {acc}\")\n",
        "\n",
        "\n",
        "# 視覺化模型訓練表現\n",
        "# - 用模型在 x_train 上的預測結果（因示範資料量極小）來繪製\n",
        "#   混淆矩陣與分類報告，觀察各類別正確與誤判情形。\n",
        "# - seaborn.heatmap 可視化混淆矩陣更直觀。\n",
        "# 注意：這裡評估不代表泛化能力（即真實的預測能力）；\n",
        "#       正式商業或學術應用專案需對 test set 作圖與報告。\n",
        "\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "\n",
        "# 取得每張圖的預測類別（argmax 將 softmax 機率轉為 0/1/2）\n",
        "y_predict = np.argmax(model.predict(x_train), axis=-1)\n",
        "\n",
        "# 混淆矩陣：列（真實）× 欄（預測）\n",
        "mat = confusion_matrix(target, y_predict)\n",
        "\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(\n",
        "    mat, square=True, annot=True, fmt=\"d\", cbar=True, cmap=\"Blues\",\n",
        "    xticklabels=labels, yticklabels=labels\n",
        ")\n",
        "plt.title(\"Confusion Matrix (混淆矩陣)\")\n",
        "plt.ylabel(\"True label (真實標籤)\")\n",
        "plt.xlabel(\"Predicted label (預測標籤)\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "De79yk-_h5-K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ==================================================\n",
        "# 8.：立互動式辨識應用（Gradio）\n",
        "# - 讓大家上傳一張八哥圖片，即時得到三類機率輸出。\n",
        "# - 這是從「建模」走向「應用/互動」的重要一步。\n",
        "# - 注意影像尺寸：本例訓練時用 256×256；Gradio 預設會回傳\n",
        "#   一張 numpy 陣列（H×W×C），若需要固定大小，也許需在\n",
        "#   gr.Image(...) 指定參數如 image_mode/shape 等。\n",
        "\n",
        "!pip install -q gradio\n",
        "import gradio as gr\n",
        "\n",
        "# 定義預測函式：\n",
        "# - 輸入 inp：一張影像（numpy 陣列，H×W×C，uint8）。\n",
        "# - expand_dims：增加 batch 維度以符合 Keras 預期 (N×H×W×C)。\n",
        "# - preprocess_input：套用 ResNetV2 前處理（轉 [-1,1]）。\n",
        "# - model.predict --> flatten --> 轉成標籤:機率 的 dict 給 Gradio。\n",
        "def classify_image(inp):\n",
        "    inp = np.expand_dims(inp, axis=0)\n",
        "    inp = preprocess_input(inp)\n",
        "    prediction = model.predict(inp).flatten()\n",
        "    return {labels[i]: float(prediction[i]) for i in range(3)}\n",
        "\n",
        "# 準備 Gradio 介面元件\n",
        "image_input = gr.Image(label=\"請上傳一張八哥照片\")\n",
        "label_output = gr.Label(\n",
        "    num_top_classes=3, label=\"AI 辨識結果\"\n",
        ")\n",
        "\n",
        "title = \"AI 八哥辨識機\"\n",
        "description = (\n",
        "    \"我能辨識 (土)八哥、白尾八哥、及家八哥。\"\n",
        "    \"請找一張八哥照片來考我吧！\"\n",
        ")\n",
        "\n",
        "# 準備範例影像路徑清單（方便一鍵測試介面）\n",
        "sample_images = []\n",
        "for folder in myna_folders:\n",
        "    thedir = os.path.join(base_dir, folder)\n",
        "    for file in os.listdir(thedir):\n",
        "        sample_images.append(os.path.join(thedir, file))\n",
        "\n",
        "# 啟動 Gradio 介面\n",
        "# - share=True：產生公開網址（教學演示很方便）。\n",
        "# - debug=True：遇到錯誤時顯示詳細訊息，利於除錯。\n",
        "gr.Interface(\n",
        "    fn=classify_image,\n",
        "    inputs=image_input,\n",
        "    outputs=label_output,\n",
        "    title=title,\n",
        "    description=description,\n",
        "    examples=sample_images\n",
        ").launch(share=True, debug=True)\n"
      ],
      "metadata": {
        "id": "bO0_d5FvkavV"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}